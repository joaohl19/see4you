# üëÅÔ∏è See4You

O **See4You** √© um projeto de *Image Captioning* (Legendagem Autom√°tica de Imagens) desenvolvido com o prop√≥sito central de **assistir pessoas com defici√™ncia visual**. O sistema processa as imagens do ambiente e descreve o cen√°rio em linguagem natural, promovendo maior autonomia e inclus√£o digital.

---

## ‚öôÔ∏è Arquitetura e Performance

Para garantir que o projeto possa ser executado em dispositivos com recursos limitados (como smartphones ou sistemas embarcados de assist√™ncia), a efici√™ncia computacional foi a prioridade m√°xima.

O modelo final utiliza a seguinte arquitetura:
* **Encoder (Vis√£o):** **MobileNetV3** ‚Äî Rede convolucional pr√©-treinada, respons√°vel por extrair a representa√ß√£o vetorial da imagem.
* **Decoder (Linguagem):** **GRU** (Gated Recurrent Unit) ‚Äî Rede recorrente respons√°vel pela gera√ß√£o de texto.

### Por que esta escolha?

Realizamos testes rigorosos comparando diferentes redes recorrentes e redes convolucionais pr√©-treinadas. A combina√ß√£o **MobileNetV3 + GRU** obteve m√©tricas pr√≥ximas √†s das outras arquiteturas, por√©m com uma redu√ß√£o significativa no tempo de execu√ß√£o

| Comparativo de Arquitetura | Ganho de Velocidade |
| :--- | :--- |
| **vs. MobileNetV3 + LSTM** | ‚ö° **2.0x mais r√°pida** |
| **vs. ResNet50 + GRU** | ‚ö°‚ö° **2.5x mais r√°pida** |

Isso significa menos lat√™ncia entre a captura da imagem e a descri√ß√£o auditiva para o usu√°rio, algo cr√≠tico para aplica√ß√µes de acessibilidade.

---
## üõ†Ô∏è Instala√ß√£o e Execu√ß√£o

O projeto foi estruturado para ser reprodut√≠vel e simples de configurar. Siga os passos abaixo para preparar o ambiente e treinar o modelo.

### 1. Clonar e Instalar Depend√™ncias

Clone este reposit√≥rio e instale as bibliotecas necess√°rias:

```bash
git clone [https://github.com/seu-usuario/see4you.git](https://github.com/seu-usuario/see4you.git)
cd see4you
pip install -r requirements.txt
```
### üì• 2. Download dos Dados

Antes de iniciar o treinamento, √© necess√°rio configurar o ambiente e baixar os dados necess√°rios. Execute o notebook **`setup.ipynb`** para realizar este processo.

**O que este notebook faz:**
* **Dataset:** Baixa e descompacta o dataset de imagens e legendas.
* **Embeddings:** Realiza o download dos embeddings pr√©-treinados **FastText**.
* **Estrutura:** Cria automaticamente as pastas `/data` e `/embeddings` no diret√≥rio raiz do projeto.

### üì• 2. Prepara√ß√£o dos Dados
Em seguida, √© necess√°rio fazer o tratamento dos dados usados no treinamento. Execute o notebook **`eda.ipynb`** para realizar este processo.

**O que este notebook faz:**
* **Dataset:** Baixa e descompacta o dataset de imagens e legendas.
* **Embeddings:** Realiza o download dos embeddings pr√©-treinados **FastText**.
* **Estrutura:** Cria automaticamente as pastas `/data` e `/embeddings` no diret√≥rio raiz do projeto.

### üî¨ 3. An√°lise e Tratamento de Dados (EDA)

Em seguida, √© necess√°rio fazer o tratamento dos dados usados no treinamento. Execute o notebook **`eda.ipynb`** para realizar este processo.

**O que este notebook faz:**
* **An√°lise Explorat√≥ria:** Gera estat√≠sticas e visualiza√ß√µes sobre as imagens e o tamanho das legendas.
* **Limpeza:** Aplica filtros e tratamentos para remover ru√≠dos ou dados inconsistentes.
* **Exporta√ß√£o:** Salva o dataset limpo na pasta **`data/cleaned`**, que ser√° a fonte oficial para o treinamento.


### üìä 4. Treinamento e Avalia√ß√£o

Com os dados organizados, execute o notebook **`training.ipynb`** para iniciar o pipeline de Deep Learning.

**O fluxo de execu√ß√£o inclui:**
1.  **Pr√©-processamento:** Carregamento dos DataLoaders e tokeniza√ß√£o.
2.  **Modelagem:** Instancia√ß√£o da arquitetura **MobileNetV3 + GRU**.
3.  **Treino:** Execu√ß√£o das √©pocas de treinamento com monitoramento da *Loss*.
4.  **Teste:** Avalia√ß√£o autom√°tica utilizando m√©tricas de similaridade no conjunto de teste.
